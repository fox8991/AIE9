{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-IqJAMkwnCF"
   },
   "source": [
    "# Session 11: Advanced Retrieval with LangChain\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "- Understand and implement multiple retrieval strategies for RAG\n",
    "- Compare naive, BM25, multi-query, parent-document, contextual compression, ensemble, and semantic chunking approaches\n",
    "- Build RAG chains over a health and wellness knowledge base using LangChain and QDrant\n",
    "\n",
    "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
    "\n",
    "We'll touch on:\n",
    "\n",
    "- Naive Retrieval\n",
    "- Best-Matching 25 (BM25)\n",
    "- Multi-Query Retrieval\n",
    "- Parent-Document Retrieval\n",
    "- Contextual Compression (a.k.a. Rerank)\n",
    "- Ensemble Retrieval\n",
    "- Semantic chunking\n",
    "\n",
    "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
    "\n",
    "There will be two breakout rooms:\n",
    "\n",
    "- ðŸ¤ Breakout Room Part #1\n",
    "  - Task 1: Getting Dependencies!\n",
    "  - Task 2: Data Collection and Preparation\n",
    "  - Task 3: Setting Up QDrant!\n",
    "  - Task 4-10: Retrieval Strategies\n",
    "- ðŸ¤ Breakout Room Part #2\n",
    "  - Activity: Evaluate with Ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rKP3hgHivpe"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ¤ Breakout Room Part #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xes8oT-xHN7"
   },
   "source": [
    "## Task 1: Getting Dependencies!\n",
    "\n",
    "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7OHJXzfyJyA"
   },
   "source": [
    "We'll also provide our OpenAI key, as well as our Cohere API key.\n",
    "\n",
    "> NOTE: Create a `.env` file in this directory with `OPENAI_API_KEY` and `COHERE_API_KEY` to avoid being prompted each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LttlDQUYgSI",
    "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iUahNiJyQbv",
    "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
   },
   "outputs": [],
   "source": [
    "if not os.environ.get(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw304iAFyRtl"
   },
   "source": [
    "## Task 2: Data Collection and Preparation\n",
    "\n",
    "We'll be using our Health and Wellness Guide - a comprehensive resource covering exercise, nutrition, sleep, stress management, habits, and common health concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A92NC2QZzCsi"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll load the wellness guide as a single document, then split it into smaller chunks using a `RecursiveCharacterTextSplitter` for our vector store. We also keep the raw (unsplit) document for use with the Parent Document Retriever and Semantic Chunker later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GshBjVRJZ6p8"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "wellness_docs = text_splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gQphb6y0C0S"
   },
   "source": [
    "Let's verify our data was loaded and split correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkUkCf7DaMiq",
    "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw documents: 1\n",
      "Split chunks: 45\n",
      "\n",
      "Example chunk:\n",
      "page_content='The Personal Wellness Guide\n",
      "A Comprehensive Resource for Health and Well-being\n",
      "\n",
      "PART 1: EXERCISE AND MOVEMENT\n",
      "\n",
      "Chapter 1: Understanding Exercise Basics\n",
      "\n",
      "Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weight, reduce the risk of disease, strengthen bones and muscles, and improve your ability to do everyday activities.' metadata={'source': 'data/HealthWellnessGuide.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw documents: {len(raw_docs)}\")\n",
    "print(f\"Split chunks: {len(wellness_docs)}\")\n",
    "print(f\"\\nExample chunk:\\n{wellness_docs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWaQpdHl0Gzc"
   },
   "source": [
    "## Task 3: Setting up QDrant!\n",
    "\n",
    "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"wellness_guide\".\n",
    "\n",
    "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
    "\n",
    "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NT8ihRJbYmMT"
   },
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    wellness_docs,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"wellness_guide\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x2SS4Rh0hiN"
   },
   "source": [
    "## Task 4: Naive RAG Chain\n",
    "\n",
    "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEH7X5Ai08FH"
   },
   "source": [
    "### R - Retrieval\n",
    "\n",
    "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
    "\n",
    "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GFDPrNBtb72o"
   },
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbBhyQjz06dx"
   },
   "source": [
    "### A - Augmented\n",
    "\n",
    "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7uSz-Dbqcoki"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlRzpb231GGJ"
   },
   "source": [
    "### G - Generation\n",
    "\n",
    "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "c-1t9H60dJLg"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg3QRGzA1M2x"
   },
   "source": [
    "### LCEL RAG Chain\n",
    "\n",
    "We're going to use LCEL to construct our chain.\n",
    "\n",
    "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0bvstS7mdOW3"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "naive_retrieval_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izKujhNb1ZG8"
   },
   "source": [
    "Let's see how this simple chain does on a few different prompts.\n",
    "\n",
    "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LI-5ueEddku9",
    "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Exercises that can help with lower back pain include:\\n\\n- Cat-Cow Stretch: Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n- Bird Dog: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- Pelvic Tilts: Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting your pelvis up slightly. Hold for 10 seconds, repeat 8-12 times.\\n- Partial Crunches: Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off the floor. Hold briefly, then lower. Do 8-12 repetitions.\\n- Knee-to-Chest Stretch: Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n\\nThese exercises are gentle and aimed at stretching and strengthening the lower back muscles to alleviate pain and improve mobility. However, it's always best to consult with a healthcare professional before starting any new exercise routine, especially if you have ongoing back issues.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "43zdcdUydtXh",
    "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep plays a vital role in maintaining overall health. It supports physical recovery by allowing the body to repair tissues and regenerate, particularly during deep sleep stages. Sleep also consolidates memories and enhances cognitive functions. Additionally, quality sleep helps regulate hormones that control growth and appetite, supports immune system function, and improves mental well-being. A consistent, restful sleep routine contributes to reducing stress, boosting the immune response, and promoting long-term health and happiness.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "lpG6rlvvvKFq",
    "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for stress and headaches include:\\n\\n- Drinking water and staying hydrated\\n- Applying cold or warm compresses to the head or neck\\n- Resting in a dark, quiet room\\n- Gentle massage of the temples and neck\\n- Using peppermint or lavender essential oils\\n- Maintaining a regular sleep schedule\\n- Practicing deep breathing exercises\\n- Engaging in progressive muscle relaxation\\n- Taking short walks, preferably in nature\\n- Listening to calming music\\n\\nThese techniques can help alleviate stress and reduce headache symptoms naturally.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsbfQmbr1leg"
   },
   "source": [
    "Overall, this is not bad! Let's see if we can make it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft1vt8HPR16w"
   },
   "source": [
    "## Task 5: Best-Matching 25 (BM25) Retriever\n",
    "\n",
    "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
    "\n",
    "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
    "\n",
    "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qdF4wuj5R-cG"
   },
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(wellness_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIjJlBQ8drKH"
   },
   "source": [
    "We'll construct the same chain - only changing the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WR15EQG7SLuw"
   },
   "outputs": [],
   "source": [
    "bm25_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gi-yXCDdvJk"
   },
   "source": [
    "Let's look at the responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "oY9qzmm3SOrF",
    "outputId": "4d4f450f-5978-460f-f242-b32407868353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on your hands and knees. Alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n- **Bird Dog:** From hands and knees, extend the opposite arm and leg while keeping your core engaged. Hold each extension for 5 seconds, then switch sides. Aim for 10 repetitions per side.\\n- **Pelvic Tilts:** Lie on your back with knees bent. Flatten your back against the floor by tightening your abs and tilting your pelvis up slightly. Hold for 10 seconds and repeat 8-12 times.\\n\\nThese exercises are gentle stretches and strengthening movements that may help alleviate and prevent lower back pain.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "igfinyneSQkh",
    "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep plays a crucial role in overall health. It helps maintain a consistent, high-quality sleep schedule which is essential for physical and mental well-being. Creating an optimal sleep environmentâ€”such as keeping the room cool, dark, and quiet, and using comfortable beddingâ€”can improve sleep quality. Practicing good sleep hygiene, like establishing a relaxing bedtime routine and limiting screen time before bed, supports better rest. Adequate sleep contributes to better immune function, mental health, and overall energy levels, thereby positively influencing overall health.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "w0H7pV_USSMQ",
    "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for stress and headaches include practicing relaxation techniques such as progressive muscle relaxation, meditation, and deep breathing exercises. Herbal teas like chamomile or valerian root may also help reduce stress and promote relaxation. Additionally, staying well-hydrated, ensuring adequate sleep, managing stress levels, and avoiding known headache triggers can be beneficial. Always consult with a healthcare provider before starting any new supplements or herbal remedies.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvg5xHaUdxCl"
   },
   "source": [
    "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #1:\n",
    "\n",
    "Give an example query where BM25 is better than embeddings and justify your answer.\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "The example query I tried is `150 minutes per week`. \n",
    "\n",
    "Since BM25 looks for the specific term(s) or value within a search query, it generally performs better than embedding based retrieval when we want to look for a specific term or value. Therefore, by looking at the source document, I find this query interesting: \"150 minutes per week\", which contains a specific value (15) and term (minutes per week). \n",
    "\n",
    "BM25 ranks the correct chunk that contains this exact query as the top chunk. By contrast, the embedding retriever ranked it second, while the first chunk it ranks is a semantically related but incorrect \"Beginner Weekly Schedule\" chunk.\n",
    "\n",
    "Specific code as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BM25 Results ===\n",
      "\n",
      "Chunk 0:\n",
      "The four main types of exercise are aerobic (cardio), strength training, flexibility, and balance exercises. A well-rounded fitness routine includes all four types. Adults should aim for at least 150 \n",
      "\n",
      "Chunk 1:\n",
      "Types of insomnia:\n",
      "- Acute insomnia: Short-term, often triggered by stress or life events\n",
      "- Chronic insomnia: Long-term, occurring at least 3 nights per week for 3 months or more\n",
      "\n",
      "Natural remedies for\n",
      "\n",
      "Chunk 2:\n",
      "Weekly Meal Planning Steps:\n",
      "1. Review your schedule for the week and identify busy days\n",
      "2. Choose 3-4 main dishes that can provide leftovers\n",
      "3. Plan for healthy snacks to avoid impulse eating\n",
      "4. Creat\n",
      "\n",
      "Chunk 3:\n",
      "Adults typically need 7-9 hours of sleep per night. Sleep occurs in cycles of about 90 minutes, alternating between REM (rapid eye movement) and non-REM sleep.\n",
      "\n",
      "The four stages of sleep:\n",
      "- Stage 1: Li\n",
      "\n",
      "==================================================\n",
      "=== Embedding Results ===\n",
      "\n",
      "Chunk 0:\n",
      "Beginner Weekly Schedule:\n",
      "- Monday: 20-minute walk + 10 minutes stretching\n",
      "- Tuesday: 15 minutes bodyweight exercises (squats, push-ups, planks)\n",
      "- Wednesday: Rest or gentle yoga\n",
      "- Thursday: 20-minute \n",
      "\n",
      "Chunk 1:\n",
      "The four main types of exercise are aerobic (cardio), strength training, flexibility, and balance exercises. A well-rounded fitness routine includes all four types. Adults should aim for at least 150 \n",
      "\n",
      "Chunk 2:\n",
      "Weekly Meal Planning Steps:\n",
      "1. Review your schedule for the week and identify busy days\n",
      "2. Choose 3-4 main dishes that can provide leftovers\n",
      "3. Plan for healthy snacks to avoid impulse eating\n",
      "4. Creat\n",
      "\n",
      "Chunk 3:\n",
      "Strategies for better balance:\n",
      "- Set clear boundaries between work and personal time\n",
      "- Learn to say no to non-essential commitments\n",
      "- Schedule personal time like you would meetings\n",
      "- Take regular brea\n",
      "\n",
      "Chunk 4:\n",
      "Daily Wellness Checklist:\n",
      "- 8 glasses of water\n",
      "- 5+ servings of fruits/vegetables\n",
      "- 30 minutes of movement\n",
      "- 7-9 hours of sleep\n",
      "- Moment of mindfulness\n",
      "- Connection with someone you care about\n",
      "- Time \n",
      "\n",
      "Chunk 5:\n",
      "Chapter 3: Building a Workout Routine\n",
      "\n",
      "Starting a new exercise routine can feel overwhelming. The key is to start slowly and gradually increase intensity and duration over time.\n",
      "\n",
      "Chunk 6:\n",
      "Digital wellness practices:\n",
      "- Set specific times to check email and social media\n",
      "- Use apps to track and limit screen time\n",
      "- Take regular breaks (20-20-20 rule for eyes)\n",
      "- Create tech-free zones (bedr\n",
      "\n",
      "Chunk 7:\n",
      "Signs of poor work-life balance:\n",
      "- Constant exhaustion\n",
      "- Neglecting personal relationships\n",
      "- No time for hobbies or self-care\n",
      "- Feeling like you're always \"on\"\n",
      "- Physical health declining\n",
      "\n",
      "Chunk 8:\n",
      "Tips for building new habits:\n",
      "- Start small (commit to just 2 minutes initially)\n",
      "- Attach new habits to existing ones (habit stacking)\n",
      "- Make the habit obvious and easy to do\n",
      "- Track your progress\n",
      "- B\n",
      "\n",
      "Chunk 9:\n",
      "Basic mindfulness meditation:\n",
      "1. Find a quiet, comfortable place to sit\n",
      "2. Close your eyes and focus on your breath\n",
      "3. Notice when your mind wanders (this is normal)\n",
      "4. Gently return attention to your\n"
     ]
    }
   ],
   "source": [
    "query = \"150 minutes per week\"\n",
    "\n",
    "print(\"=== BM25 Results ===\")\n",
    "bm25_docs = bm25_retriever.invoke(query)\n",
    "for i, doc in enumerate(bm25_docs):\n",
    "    print(f\"\\nChunk {i}:\\n{doc.page_content[:200]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "print(\"=== Embedding Results ===\")\n",
    "embedding_docs = naive_retriever.invoke(query)\n",
    "for i, doc in enumerate(embedding_docs):\n",
    "    print(f\"\\nChunk {i}:\\n{doc.page_content[:200]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-dcbFn2vpZF"
   },
   "source": [
    "## Task 6: Contextual Compression (Using Reranking)\n",
    "\n",
    "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
    "\n",
    "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
    "\n",
    "The basic idea here is this:\n",
    "\n",
    "- We retrieve lots of documents that are very likely related to our query vector\n",
    "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
    "\n",
    "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
    "\n",
    "All we need to do is the following:\n",
    "\n",
    "- Create a basic retriever\n",
    "- Create a compressor (reranker, in this case)\n",
    "\n",
    "That's it!\n",
    "\n",
    "Let's see it in the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "psHvO2K1v_ZQ"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=naive_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TA9RB2x-j7P"
   },
   "source": [
    "Let's create our chain again, and see how this does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1BXqmxvHwX6T"
   },
   "outputs": [],
   "source": [
    "contextual_compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "V3iGpokswcBb",
    "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exercises that can help alleviate lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on your hands and knees. Arch your back up (like a cat) then let it sag down (like a cow). Perform 10-15 repetitions.\\n- **Bird Dog:** From hands and knees, extend your opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- **Pelvic Tilts:** Lie on your back with knees bent. Flatten your lower back against the floor by tightening your abs and tilting your pelvis slightly. Hold for 10 seconds and repeat 8-12 times.\\n\\nThese gentle stretching and strengthening exercises can help relieve lower back discomfort and prevent future issues.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "7u_k0i4OweUd",
    "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep significantly impacts overall health by supporting physical repair, mental well-being, and cognitive function. During sleep, your body repairs tissues, consolidates memories, and releases hormones that regulate growth and appetite. Adequate sleepâ€”typically 7-9 hours per nightâ€”also helps maintain a healthy immune system, emotional stability, and proper metabolic function. Poor sleep or sleep disorders like insomnia can negatively affect these processes, leading to health issues. Creating an optimal sleep environment can enhance sleep quality and overall health.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "zn1EqaGqweXN",
    "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for managing stress and headaches include practicing deep breathing exercises, progressive muscle relaxation, and grounding techniques. Taking short walks in nature and listening to calming music can also help reduce stress. For headaches specifically, remedies include staying well-hydrated by drinking water, applying cold or warm compresses to the head or neck, resting in a dark, quiet room, gentle massage of the temples and neck, using peppermint or lavender essential oils, and maintaining a regular sleep schedule.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_compression_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEbT0g2S-mZ4"
   },
   "source": [
    "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqbghrBEQNn5"
   },
   "source": [
    "## Task 7: Multi-Query Retriever\n",
    "\n",
    "Typically in RAG we have a single query - the one provided by the user.\n",
    "\n",
    "What if we had....more than one query!\n",
    "\n",
    "In essence, a Multi-Query Retriever works by:\n",
    "\n",
    "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
    "2. Retrieving documents for each query.\n",
    "3. Using all unique retrieved documents as context\n",
    "\n",
    "So, how is it to set-up? Not bad! Let's see it down below!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pfM26ReXQjzU"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=naive_retriever, llm=chat_model\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1vRc129jQ5WW"
   },
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "CGgNuOb3Q3M9",
    "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on your hands and knees. Alternate between arching your back up (cat pose) and letting it sag down (cow pose). Perform 10-15 repetitions.\\n\\n- **Bird Dog:** From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold each extension for about 5 seconds, then switch sides. Aim for 10 repetitions per side.\\n\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over your chest, tighten your stomach muscles, and lift your shoulders off the floor. Hold briefly and then lower back down. Do 8-12 repetitions.\\n\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat on the floor. Hold the stretch for 15-30 seconds and switch legs.\\n\\n- **Pelvic Tilts:** Lie on your back with knees bent. Flatten your back against the floor by tightening your abs and tilting your pelvis upward slightly. Hold for about 10 seconds and repeat 8-12 times.\\n\\nThese exercises, along with gentle stretching and maintaining proper posture, can help alleviate lower back pain. It is advisable to consult with a healthcare professional before starting any new exercise routine, especially if you have ongoing back issues.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "aAlSthxrRDBC",
    "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep plays a vital role in overall health by supporting physical, mental, and cognitive well-being. During sleep, the body repairs tissues, regulates hormones related to growth and appetite, and consolidates memories, which are essential for healthy functioning. Lack of sufficient quality sleep can lead to issues such as fatigue, immune dysfunction, mental health problems, and impaired cognitive performance. Maintaining good sleep hygiene, such as keeping a consistent schedule, creating a comfortable sleep environment, and practicing relaxation routines, can promote better sleep and thereby enhance overall health.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "Uv1mpCK8REs4",
    "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for stress and headaches include:\\n\\n- Drinking plenty of water to stay hydrated.\\n- Applying cold or warm compresses to your head or neck.\\n- Resting in a dark, quiet room.\\n- Gentle massage of your temples and neck.\\n- Using peppermint or lavender essential oils.\\n- Maintaining a regular sleep schedule.\\n- Practicing immediate stress relief techniques such as deep breathing, progressive muscle relaxation, grounding exercises, taking short walks, or listening to calming music.\\n\\nThese remedies can help alleviate headache symptoms and reduce stress naturally.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #2:\n",
    "\n",
    "Explain how generating multiple reformulations of a user query can improve recall.\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "Using a single user query to retrieve might miss relevant chunks due to the phrasing/wording of the query (e.g., \"workout\" vs \"exercise\"). By contrast, when we generate multiple variations that phrase similar question in different ways, we increase the diversity of the queries that cover different ways of phrasing this similar question semantically. As a result, the union of the chunks that gets retrieved will have a higher chance to cover more ground truth chunks, and this will improve the recall since more relevant chunks get retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDEawBf_d_3G"
   },
   "source": [
    "## Task 8: Parent Document Retriever\n",
    "\n",
    "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
    "\n",
    "1. We split the full document into large \"parent\" chunks (e.g. 2000 characters).\n",
    "2. Each parent chunk is further split into smaller \"child\" chunks (e.g. 400 characters).\n",
    "3. The child chunks are stored in a VectorStore, while the parent chunks are stored in an in-memory docstore.\n",
    "4. When we query our Retriever, we do a similarity search comparing our query vector to the child chunks.\n",
    "5. Instead of returning the child chunks, we return their associated parent chunks.\n",
    "\n",
    "The basic idea is:\n",
    "\n",
    "- **Search** for small, focused chunks (better semantic matching)\n",
    "- **Return** big chunks (richer surrounding context)\n",
    "\n",
    "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
    "\n",
    "Let's start by defining our parent and child splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qJ53JJuMd_ZH"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOpXfVUH3gL3"
   },
   "source": [
    "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
    "\n",
    "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzFc-_9HlGQ-",
    "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
   },
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"wellness_parent_child\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_document_vectorstore = QdrantVectorStore(\n",
    "    collection_name=\"wellness_parent_child\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_g95FA3s6w"
   },
   "source": [
    "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BpWVjPf4fLUp"
   },
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=parent_document_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoYmSWfE32Zo"
   },
   "source": [
    "By default, this is empty as we haven't added any documents - let's add some now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "iQ2ZzfKigMZc"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever.add_documents(raw_docs, ids=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI7Tip1335rE"
   },
   "source": [
    "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Qq_adt2KlSqp"
   },
   "outputs": [],
   "source": [
    "parent_document_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNolUVQb4Apt"
   },
   "source": [
    "Let's give it a whirl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "TXB5i89Zly5W",
    "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To help with lower back pain, some recommended exercises include:\\n\\n- **Cat-Cow Stretch:** On hands and knees, alternate arching your back up (cat) and sagging it down (cow). Aim for 10-15 repetitions.\\n- **Bird Dog:** From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over chest, tighten your stomach muscles, and lift your shoulders off the floor. Do 8-12 repetitions.\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n- **Pelvic Tilts:** Lie on your back with knees bent, flatten your back against the floor by tightening your abs and tilting your pelvis upward. Hold for 10 seconds. Repeat 8-12 times.\\n\\nThese exercises can help alleviate discomfort and prevent future episodes of lower back pain. Remember to perform them gently and consult a healthcare professional if you have any concerns or persistent pain.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "V5F1T-wNl3cg",
    "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep significantly impacts overall health by supporting multiple vital functions. During sleep, the body repairs tissues, balances hormones that regulate growth and appetite, and strengthens the immune system. Adequate sleep (7-9 hours for adults) is essential for mental well-being, cognitive functions like memory consolidation, and emotional regulation. Poor sleep quality or insufficient sleep can lead to issues such as fatigue, decreased concentration, weakened immunity, and increased risk of chronic conditions. Maintaining good sleep hygieneâ€”like having a consistent sleep schedule, creating a relaxing bedtime routine, and optimizing the sleep environmentâ€”can improve sleep quality and, in turn, enhance overall health.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "ZqARszGzvGcG",
    "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for stress and headaches include practicing deep breathing exercises, engaging in mindfulness or meditation, performing gentle stretching or yoga, taking warm baths, listening to calming music, and using essential oils like peppermint or lavender. Additionally, staying well-hydrated by drinking water and maintaining a regular sleep schedule can help manage headaches and reduce stress. Resting in a dark, quiet room and self-massage of the temples and neck are also effective natural approaches.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B41cj42s4DPM"
   },
   "source": [
    "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUrIBKl_TwS9"
   },
   "source": [
    "## Task 9: Ensemble Retriever\n",
    "\n",
    "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
    "\n",
    "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
    "\n",
    "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8j7jpZsKTxic"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
    "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retriever_list, weights=equal_weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpo9Psl5hhJ-"
   },
   "source": [
    "We'll pack *all* of these retrievers together in an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KZ__EZwpUKkd"
   },
   "outputs": [],
   "source": [
    "ensemble_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSsvHpRMj24L"
   },
   "source": [
    "Let's look at our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "0lMvqL88UQI-",
    "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exercises that can help alleviate lower back pain include:\\n\\n1. Cat-Cow Stretch: Start on hands and knees, alternate arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n\\n2. Bird Dog: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n\\n3. Pelvic Tilts: Lie on your back with knees bent, tighten your abs and tilt your pelvis up slightly to flatten your back against the floor. Hold for 10 seconds and repeat 8-12 times.\\n\\n4. Partial Crunches: Lie on your back with knees bent, cross arms over chest, tighten stomach muscles, and raise shoulders off the floor briefly. Do 8-12 repetitions.\\n\\n5. Knee-to-Chest Stretch: Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n\\nThese exercises are gentle stretches and strengthening movements that can help relieve lower back discomfort and prevent future issues.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "MNFWLYECURI1",
    "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep has a significant impact on overall health. During sleep, the body repairs tissues, consolidates memories, and regulates hormones that influence growth and appetite. Adequate sleep (7-9 hours per night) supports physical health, mental well-being, and cognitive function. Poor sleep or sleep-related issues like insomnia can lead to problems such as increased stress, impaired immune function, and decreased mental clarity. Creating a healthy sleep environment and practicing good sleep hygieneâ€”such as maintaining a regular sleep schedule, creating a relaxing bedtime routine, and ensuring a comfortable, dark, quiet bedroomâ€”can promote better sleep quality and, consequently, improve overall health.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "A7qbHfWgUR4c",
    "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some natural remedies for stress and headaches include:\\n\\n- Deep breathing exercises (such as inhaling for 4 counts, holding, exhaling, and holding again)\\n- Progressive muscle relaxation, tensing and releasing muscle groups\\n- Grounding techniques, like naming things you see, hear, feel, smell, and taste\\n- Taking short walks, preferably in nature\\n- Listening to calming music\\n- Engaging in mindfulness and meditation practices\\n- Resting in a dark, quiet room\\n- Gentle massage of temples and neck\\n- Using essential oils like peppermint or lavender\\n- Applying cold or warm compresses to the head or neck\\n- Staying well-hydrated by drinking water\\n- Maintaining a regular sleep schedule\\n\\nThese approaches can help manage stress and alleviate headache symptoms naturally.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MopbkNJAXVaN"
   },
   "source": [
    "## Task 10: Semantic Chunking\n",
    "\n",
    "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
    "\n",
    "Essentially, Semantic Chunking is implemented by:\n",
    "\n",
    "1. Embedding all sentences in the corpus.\n",
    "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
    "  - `percentile`\n",
    "  - `standard_deviation`\n",
    "  - `interquartile`\n",
    "  - `gradient`\n",
    "3. Each sequence of related sentences is kept as a document!\n",
    "\n",
    "Let's see how to implement this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9ciZbFEldv_"
   },
   "source": [
    "We'll use the `percentile` thresholding method for this example which will:\n",
    "\n",
    "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "66EIEWiEYl5y"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqoKmz12mhRW"
   },
   "source": [
    "Now we can split our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ROcV7o68ZIq7"
   },
   "outputs": [],
   "source": [
    "semantic_documents = semantic_chunker.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8-LNC-Xmjex"
   },
   "source": [
    "Let's create a new vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "h3sl9QjyZhIe"
   },
   "outputs": [],
   "source": [
    "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
    "    semantic_documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"wellness_guide_semantic_chunks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh_r_-LHmmKn"
   },
   "source": [
    "We'll use naive retrieval for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "odVyDUHwZftc"
   },
   "outputs": [],
   "source": [
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkeiv_ojmp6G"
   },
   "source": [
    "Finally we can create our classic chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xWE_0J0mZveG"
   },
   "outputs": [],
   "source": [
    "semantic_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5pfjLQ3ms9_"
   },
   "source": [
    "And view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "0lN2j-e4Z0SD",
    "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on your hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over chest, tighten stomach muscles, and raise shoulders off the floor. Hold briefly, then lower. Do 8-12 repetitions.\\n\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n\\n- **Pelvic Tilts:** Lie on your back with knees bent, flatten your back against the floor by tightening your abs and tilting your pelvis up slightly. Hold for 10 seconds, repeat 8-12 times.\\n\\nAdditionally, starting with gentle movements like walking and stretching, and gradually increasing activity can be beneficial. It's always best to consult with a healthcare provider before starting new exercises, especially if you have ongoing pain or other health conditions.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "xdqfBH1SZ3f9",
    "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sleep plays a vital role in overall health by supporting physical restoration, mental well-being, and cognitive function. During sleep, the body repairs tissues, consolidates memories, and releases hormones that regulate growth and appetite. Adequate sleep (7-9 hours per night for adults) helps maintain a healthy immune system, reduces the risk of chronic conditions, improves mood, and enhances concentration and learning. Good sleep hygiene and creating an optimal sleep environment contribute significantly to sleep quality, which in turn positively impacts overall health.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "rAcAObZnZ4o6",
    "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Some natural remedies for stress include deep breathing exercises, progressive muscle relaxation, grounding techniques (such as naming things you see, hear, feel, smell, and taste), taking short walks in nature, listening to calming music, practicing mindfulness and meditation, and engaging in hobbies. \\n\\nFor headaches, natural remedies involve staying hydrated by drinking water, applying cold or warm compresses to the head or neck, resting in a dark, quiet room, giving yourself gentle massages of the temples and neck, using peppermint or lavender essential oils, and maintaining a regular sleep schedule. \\n\\nRemember, it's always best to consult with a healthcare professional if you experience persistent or severe symptoms.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â“ Question #3:\n",
    "\n",
    "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "When the sentences are short and highly repetitive, the distance metric in between each sentence is very likely to be very small, and therefore when we use semantic chunking (e.g., when using the default 95-th percentile score to split), it's very likely that a high number of sentences ended up in a big chunk.\n",
    "\n",
    "Some ways to adjust the algorithm:\n",
    "\n",
    "- Lower the percentile (i.e., the breakpoint threshold) from the default 95-th percentile to something like 80 or even 50-th percentile to creating more chunks. But this may also not lead to very meaningful boundaries between chunks.\n",
    "- Add a max chunk size to force split\n",
    "- Revert to the recursive chunking which may better suit this highly repetitive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk2n3-pnVWDJ"
   },
   "source": [
    "---\n",
    "\n",
    "# ðŸ¤ Breakout Room Part #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SkJLYwMVZkj"
   },
   "source": [
    "### ðŸ—ï¸ Activity #1:\n",
    "\n",
    "Your task is to evaluate the various Retriever methods against each other.\n",
    "\n",
    "You are expected to:\n",
    "\n",
    "1. Create a \"golden dataset\"\n",
    " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
    "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
    " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparison between them\n",
    "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
    "\n",
    "Your analysis should factor in:\n",
    "  - Cost\n",
    "  - Latency\n",
    "  - Performance\n",
    "\n",
    "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWAr16a5XMub"
   },
   "source": [
    "##### HINTS:\n",
    "\n",
    "- LangSmith provides detailed information about latency and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tgDICngKXLGK"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - Advanced Retrieval - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/5970106.py:8: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/5970106.py:9: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cd408cf80542c199cb9f4599b32db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbdd4675c164df4beb0558faf9cec6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9264ffe5244598d383f7937c9a2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2406aa60c24060add1b4afb77a4313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d58f84ee9147f0acd75f5239cd6e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying EmbeddingExtractor:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0fc838c2e44306b12169ed50b24c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying ThemesExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a1325e339743a18761c24859e63082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NERExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84815efc2fbf44a683679b018df3b095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CosineSimilarityBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb490fb5e1e4c25ad025480ce02151c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping multi_hop_abstract_query_synthesizer due to unexpected error: No relationships match the provided condition. Cannot form clusters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b8f9e28c9946d98b6210508aeebb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7e2b0f1ea142c0acfac3732493bbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918604f85a664bb19ae4d1e28e561e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 16\n",
      "\n",
      "Distribution:\n",
      "synthesizer_name\n",
      "single_hop_specific_query_synthesizer    8\n",
      "multi_hop_specific_query_synthesizer     8\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I perform a Chest Opener exercise to h...</td>\n",
       "      <td>[PART 1: EXERCISE AND MOVEMENT\\n\\nChapter 1: U...</td>\n",
       "      <td>To perform a Chest Opener exercise for neck an...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do Cat-Cow Stretch help?</td>\n",
       "      <td>[PART 1: EXERCISE AND MOVEMENT\\n\\nChapter 1: U...</td>\n",
       "      <td>Cat-Cow Stretch is recommended for lower back ...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is insomnia and what are some natural rem...</td>\n",
       "      <td>[PART 2: NUTRITION AND DIET\\n\\nChapter 4: Fund...</td>\n",
       "      <td>Insomnia is difficulty falling asleep, staying...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wht is greek yogrt gud for in a helthy diet an...</td>\n",
       "      <td>[PART 2: NUTRITION AND DIET\\n\\nChapter 4: Fund...</td>\n",
       "      <td>Greek yogurt is listed as an afternoon snack o...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>MISSPELLED</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Chapter 18 say for boost immune?</td>\n",
       "      <td>[PART 5: BUILDING HEALTHY HABITS Chapter 13: T...</td>\n",
       "      <td>Chapter 18 says to boost immune function you s...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What Chapter 19 say about how to get better wo...</td>\n",
       "      <td>[PART 5: BUILDING HEALTHY HABITS Chapter 13: T...</td>\n",
       "      <td>Chapter 19 explains that maintaining balance b...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I do Meditation for stress? I want to k...</td>\n",
       "      <td>[PART 4: STRESS MANAGEMENT AND MENTAL WELLNESS...</td>\n",
       "      <td>Basic mindfulness meditation steps is: Find a ...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do you do progressive muscle relaxation fo...</td>\n",
       "      <td>[PART 4: STRESS MANAGEMENT AND MENTAL WELLNESS...</td>\n",
       "      <td>Progressive muscle relaxation is a technique f...</td>\n",
       "      <td>Wellness Enthusiast</td>\n",
       "      <td>POOR_GRAMMAR</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wut are teh main stratgees for work-life balan...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Chapter 19 recomends several stratgees for wor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>According to Chapter 10 and related sections, ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 4: STRESS MANAGEMENT AND MENT...</td>\n",
       "      <td>Chapter 10 explains that stress is the body's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does understanding the habit loop describe...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Understanding the habit loop from Chapter 13, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can the evening wind-down routines describ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>The evening wind-down routines outlined in Cha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wut chptr 19 say bout work-life balnce?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Chapter 19 says that maintaining balance betwe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wut is the habbit loop in chaptur 13 and how c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>The habit loop in Chapter 13 has three parts: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wht are the main physcal and mentl symptms of ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 4: STRESS MANAGEMENT AND MENT...</td>\n",
       "      <td>In Chapter 10, the main physical symptoms of s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are the key elements of a wellness-focuse...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>According to Chapter 14, a wellness-focused mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How can I perform a Chest Opener exercise to h...   \n",
       "1                        How do Cat-Cow Stretch help?   \n",
       "2   What is insomnia and what are some natural rem...   \n",
       "3   wht is greek yogrt gud for in a helthy diet an...   \n",
       "4               What Chapter 18 say for boost immune?   \n",
       "5   What Chapter 19 say about how to get better wo...   \n",
       "6   How do I do Meditation for stress? I want to k...   \n",
       "7   How do you do progressive muscle relaxation fo...   \n",
       "8   Wut are teh main stratgees for work-life balan...   \n",
       "9   According to Chapter 10 and related sections, ...   \n",
       "10  How does understanding the habit loop describe...   \n",
       "11  How can the evening wind-down routines describ...   \n",
       "12            wut chptr 19 say bout work-life balnce?   \n",
       "13  wut is the habbit loop in chaptur 13 and how c...   \n",
       "14  Wht are the main physcal and mentl symptms of ...   \n",
       "15  What are the key elements of a wellness-focuse...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [PART 1: EXERCISE AND MOVEMENT\\n\\nChapter 1: U...   \n",
       "1   [PART 1: EXERCISE AND MOVEMENT\\n\\nChapter 1: U...   \n",
       "2   [PART 2: NUTRITION AND DIET\\n\\nChapter 4: Fund...   \n",
       "3   [PART 2: NUTRITION AND DIET\\n\\nChapter 4: Fund...   \n",
       "4   [PART 5: BUILDING HEALTHY HABITS Chapter 13: T...   \n",
       "5   [PART 5: BUILDING HEALTHY HABITS Chapter 13: T...   \n",
       "6   [PART 4: STRESS MANAGEMENT AND MENTAL WELLNESS...   \n",
       "7   [PART 4: STRESS MANAGEMENT AND MENTAL WELLNESS...   \n",
       "8   [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "9   [<1-hop>\\n\\nPART 4: STRESS MANAGEMENT AND MENT...   \n",
       "10  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "11  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "12  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "13  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "14  [<1-hop>\\n\\nPART 4: STRESS MANAGEMENT AND MENT...   \n",
       "15  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "\n",
       "                                            reference         persona_name  \\\n",
       "0   To perform a Chest Opener exercise for neck an...  Wellness Enthusiast   \n",
       "1   Cat-Cow Stretch is recommended for lower back ...  Wellness Enthusiast   \n",
       "2   Insomnia is difficulty falling asleep, staying...  Wellness Enthusiast   \n",
       "3   Greek yogurt is listed as an afternoon snack o...  Wellness Enthusiast   \n",
       "4   Chapter 18 says to boost immune function you s...  Wellness Enthusiast   \n",
       "5   Chapter 19 explains that maintaining balance b...  Wellness Enthusiast   \n",
       "6   Basic mindfulness meditation steps is: Find a ...  Wellness Enthusiast   \n",
       "7   Progressive muscle relaxation is a technique f...  Wellness Enthusiast   \n",
       "8   Chapter 19 recomends several stratgees for wor...                  NaN   \n",
       "9   Chapter 10 explains that stress is the body's ...                  NaN   \n",
       "10  Understanding the habit loop from Chapter 13, ...                  NaN   \n",
       "11  The evening wind-down routines outlined in Cha...                  NaN   \n",
       "12  Chapter 19 says that maintaining balance betwe...                  NaN   \n",
       "13  The habit loop in Chapter 13 has three parts: ...                  NaN   \n",
       "14  In Chapter 10, the main physical symptoms of s...                  NaN   \n",
       "15  According to Chapter 14, a wellness-focused mo...                  NaN   \n",
       "\n",
       "        query_style query_length                       synthesizer_name  \n",
       "0   PERFECT_GRAMMAR       MEDIUM  single_hop_specific_query_synthesizer  \n",
       "1      POOR_GRAMMAR        SHORT  single_hop_specific_query_synthesizer  \n",
       "2   WEB_SEARCH_LIKE        SHORT  single_hop_specific_query_synthesizer  \n",
       "3        MISSPELLED         LONG  single_hop_specific_query_synthesizer  \n",
       "4      POOR_GRAMMAR        SHORT  single_hop_specific_query_synthesizer  \n",
       "5      POOR_GRAMMAR         LONG  single_hop_specific_query_synthesizer  \n",
       "6      POOR_GRAMMAR       MEDIUM  single_hop_specific_query_synthesizer  \n",
       "7      POOR_GRAMMAR         LONG  single_hop_specific_query_synthesizer  \n",
       "8               NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "9               NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "10              NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "11              NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "12              NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "13              NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "14              NaN          NaN   multi_hop_specific_query_synthesizer  \n",
       "15              NaN          NaN   multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 1: Generate the golden dataset\n",
    "\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(\n",
    "    raw_docs,\n",
    "    testset_size=15\n",
    ")\n",
    "\n",
    "df = dataset.to_pandas()\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nDistribution:\\n{df['synthesizer_name'].value_counts()}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing LLMContextRecall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import LLMContextRecall\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing Faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import Faithfulness\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing FactualCorrectness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import FactualCorrectness\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing ResponseRelevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import ResponseRelevancy\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing ContextEntityRecall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import ContextEntityRecall\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:6: DeprecationWarning: Importing NoiseSensitivity from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import NoiseSensitivity\n",
      "  from ragas.metrics import (\n",
      "/var/folders/r4/cqrwpld94ldc4rgfhq1fbx8h0000gn/T/ipykernel_75769/869665806.py:11: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Evaluating: naive\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503937ec2afa4b31a6eb5991664ce57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[59]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive: {'context_recall': 0.9458, 'faithfulness': 0.7686, 'factual_correctness(mode=f1)': 0.6469, 'answer_relevancy': 0.9464, 'context_entity_recall': 0.3357, 'noise_sensitivity(mode=relevant)': 0.0784}\n",
      "\n",
      "==================================================\n",
      "Evaluating: bm25\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14563e6d9643419aa311f0b2cef3231e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm25: {'context_recall': 0.5260, 'faithfulness': 0.5425, 'factual_correctness(mode=f1)': 0.5056, 'answer_relevancy': 0.7144, 'context_entity_recall': 0.1844, 'noise_sensitivity(mode=relevant)': 0.0699}\n",
      "\n",
      "==================================================\n",
      "Evaluating: contextual_compression\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdd8429ff074f85b18713f3f1a2c131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contextual_compression: {'context_recall': 0.9260, 'faithfulness': 0.6594, 'factual_correctness(mode=f1)': 0.7194, 'answer_relevancy': 0.9420, 'context_entity_recall': 0.3171, 'noise_sensitivity(mode=relevant)': 0.0500}\n",
      "\n",
      "==================================================\n",
      "Evaluating: multi_query\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9748ea3cb65345cf93290f130a730045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[17]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[71]: TimeoutError()\n",
      "Exception raised in Job[89]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_query: {'context_recall': 0.9563, 'faithfulness': 0.6791, 'factual_correctness(mode=f1)': 0.6663, 'answer_relevancy': 0.9430, 'context_entity_recall': 0.2684, 'noise_sensitivity(mode=relevant)': 0.0647}\n",
      "\n",
      "==================================================\n",
      "Evaluating: parent_document\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8c1deb2058467cbc862b24dcfbd261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_document: {'context_recall': 0.9875, 'faithfulness': 0.6668, 'factual_correctness(mode=f1)': 0.6613, 'answer_relevancy': 0.9447, 'context_entity_recall': 0.3413, 'noise_sensitivity(mode=relevant)': 0.1433}\n",
      "\n",
      "==================================================\n",
      "Evaluating: ensemble\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b49a15a8254b279957986e74f8963c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[71]: TimeoutError()\n",
      "Exception raised in Job[77]: TimeoutError()\n",
      "Exception raised in Job[83]: TimeoutError()\n",
      "Exception raised in Job[89]: TimeoutError()\n",
      "Exception raised in Job[95]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble: {'context_recall': 0.9750, 'faithfulness': 0.7018, 'factual_correctness(mode=f1)': 0.6656, 'answer_relevancy': 0.9452, 'context_entity_recall': 0.2381, 'noise_sensitivity(mode=relevant)': 0.1731}\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Evaluate the retrievers\n",
    "\n",
    "import copy, time\n",
    "from ragas import evaluate, EvaluationDataset, RunConfig\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall, Faithfulness, FactualCorrectness,\n",
    "    ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    ")\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "retriever_chains = {\n",
    "    \"naive\": naive_retrieval_chain,\n",
    "    \"bm25\": bm25_retrieval_chain,\n",
    "    \"contextual_compression\": contextual_compression_retrieval_chain,\n",
    "    \"multi_query\": multi_query_retrieval_chain,\n",
    "    \"parent_document\": parent_document_retrieval_chain,\n",
    "    \"ensemble\": ensemble_retrieval_chain,\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for name, chain in retriever_chains.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Evaluating: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    retriever_dataset = copy.deepcopy(dataset)\n",
    "\n",
    "    for test_row in retriever_dataset:\n",
    "        response = chain.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "        test_row.eval_sample.response = response[\"response\"].content\n",
    "        test_row.eval_sample.retrieved_contexts = [\n",
    "            doc.page_content for doc in response[\"context\"]\n",
    "        ]\n",
    "        time.sleep(5)\n",
    "\n",
    "    ## Avoid the NaN issue for persona_name, query_style, query_length in multi-hop queries\n",
    "    samples = [test_row.eval_sample for test_row in retriever_dataset]\n",
    "    eval_dataset = EvaluationDataset(samples=samples)\n",
    "\n",
    "    result = evaluate(\n",
    "        dataset=eval_dataset,\n",
    "        metrics=[\n",
    "            LLMContextRecall(), Faithfulness(), FactualCorrectness(),\n",
    "            ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()\n",
    "        ],\n",
    "        llm=evaluator_llm,\n",
    "        run_config=custom_run_config,\n",
    "    )\n",
    "\n",
    "    all_results[name] = result\n",
    "    print(f\"{name}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity(mode=relevant)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive</th>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.646875</td>\n",
       "      <td>0.946393</td>\n",
       "      <td>0.335747</td>\n",
       "      <td>0.078386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25</th>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.542519</td>\n",
       "      <td>0.505625</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.184357</td>\n",
       "      <td>0.069874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_compression</th>\n",
       "      <td>0.926042</td>\n",
       "      <td>0.659385</td>\n",
       "      <td>0.719375</td>\n",
       "      <td>0.942020</td>\n",
       "      <td>0.317060</td>\n",
       "      <td>0.050038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_query</th>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.679107</td>\n",
       "      <td>0.666250</td>\n",
       "      <td>0.942995</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>0.064683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_document</th>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.666752</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.944654</td>\n",
       "      <td>0.341270</td>\n",
       "      <td>0.143266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.701780</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.945188</td>\n",
       "      <td>0.238079</td>\n",
       "      <td>0.173059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_recall  faithfulness  \\\n",
       "naive                         0.945833      0.768603   \n",
       "bm25                          0.526042      0.542519   \n",
       "contextual_compression        0.926042      0.659385   \n",
       "multi_query                   0.956250      0.679107   \n",
       "parent_document               0.987500      0.666752   \n",
       "ensemble                      0.975000      0.701780   \n",
       "\n",
       "                        factual_correctness(mode=f1)  answer_relevancy  \\\n",
       "naive                                       0.646875          0.946393   \n",
       "bm25                                        0.505625          0.714447   \n",
       "contextual_compression                      0.719375          0.942020   \n",
       "multi_query                                 0.666250          0.942995   \n",
       "parent_document                             0.661250          0.944654   \n",
       "ensemble                                    0.665625          0.945188   \n",
       "\n",
       "                        context_entity_recall  \\\n",
       "naive                                0.335747   \n",
       "bm25                                 0.184357   \n",
       "contextual_compression               0.317060   \n",
       "multi_query                          0.268373   \n",
       "parent_document                      0.341270   \n",
       "ensemble                             0.238079   \n",
       "\n",
       "                        noise_sensitivity(mode=relevant)  \n",
       "naive                                           0.078386  \n",
       "bm25                                            0.069874  \n",
       "contextual_compression                          0.050038  \n",
       "multi_query                                     0.064683  \n",
       "parent_document                                 0.143266  \n",
       "ensemble                                        0.173059  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    name: result.to_pandas().mean(numeric_only=True).to_dict()\n",
    "    for name, result in all_results.items()\n",
    "}).T\n",
    "\n",
    "comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import uuid\n",
    "\n",
    "langsmith_client = Client()\n",
    "\n",
    "dataset_name = f\"Advanced Retrieval - AIE9 - {uuid.uuid4()}\"\n",
    "\n",
    "langsmith_dataset = langsmith_client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Advanced Retrieval Class\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Use langsmith to evaluate the cost and latency\n",
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  langsmith_client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: naive\n",
      "View the evaluation results for experiment: 'naive-b3b5ef56' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=949a2a21-86d1-43d0-8b8d-523e6fd90e61\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d2f669b9924a138a31fb4408fb73d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: bm25\n",
      "View the evaluation results for experiment: 'bm25-59c47242' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=980593bf-9d80-42a0-9571-fdcf5b5fbdba\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5aa1b8c4884f189e29a8700732926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: contextual_compression\n",
      "View the evaluation results for experiment: 'contextual_compression-c4b42579' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=753e4491-992f-4a76-b1b1-82ba4215c93d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532643c2932745f6bedc64f8afb10e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: multi_query\n",
      "View the evaluation results for experiment: 'multi_query-fe3a25ec' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=c30d8659-b683-496e-bb85-d121f114de61\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d531cf8618b447d971d69ce5e3af917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: parent_document\n",
      "View the evaluation results for experiment: 'parent_document-b8f22c56' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=6dcea39f-06be-4ee7-aba4-b761e53bec28\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5d6414936043d98c808f0f144509c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running LangSmith evaluation for: ensemble\n",
      "View the evaluation results for experiment: 'ensemble-a775755a' at:\n",
      "https://smith.langchain.com/o/991456bb-c3e2-422e-957d-4e5bfe176b65/datasets/700c19dd-3cb8-4710-94e7-cc8cff81a136/compare?selectedSessions=3e11d5b0-3a07-4fde-89a6-3000dbbc5a8f\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6a2b23aa694ffba12cd723479dfaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from openevals.llm import create_llm_as_judge\n",
    "from langsmith.evaluation import evaluate as ls_evaluate\n",
    "\n",
    "qa_evaluator = create_llm_as_judge(\n",
    "    prompt=(\n",
    "        \"You are evaluating a QA system. Given the input, assess whether the prediction is correct.\\n\\n\"\n",
    "        \"Input: {inputs}\\n\"\n",
    "        \"Prediction: {outputs}\\n\"\n",
    "        \"Reference answer: {reference_outputs}\\n\\n\"\n",
    "        \"Is the prediction correct? Return 1 if correct, 0 if incorrect.\"\n",
    "    ),\n",
    "    feedback_key=\"qa\",\n",
    "    model=\"openai:gpt-4.1\",\n",
    ")\n",
    "\n",
    "labeled_helpfulness_evaluator = create_llm_as_judge(\n",
    "    prompt=(\n",
    "        \"You are assessing a submission based on the following criterion:\\n\\n\"\n",
    "        \"helpfulness: Is this submission helpful to the user, \"\n",
    "        \"taking into account the correct reference answer?\\n\\n\"\n",
    "        \"Input: {inputs}\\n\"\n",
    "        \"Submission: {outputs}\\n\"\n",
    "        \"Reference answer: {reference_outputs}\\n\\n\"\n",
    "        \"Does the submission meet the criterion? Return 1 if yes, 0 if no.\"\n",
    "    ),\n",
    "    feedback_key=\"helpfulness\",\n",
    "    model=\"openai:gpt-4.1\",\n",
    ")\n",
    "\n",
    "def make_chain_target(chain):\n",
    "    \"\"\"Wrap chain.invoke so it returns just the answer string.\"\"\"\n",
    "    def target(inputs):\n",
    "        result = chain.invoke(inputs)\n",
    "        return result[\"response\"].content\n",
    "    return target\n",
    "\n",
    "for name, chain in retriever_chains.items():\n",
    "    print(f\"\\nRunning LangSmith evaluation for: {name}\")\n",
    "    ls_evaluate(\n",
    "        make_chain_target(chain),\n",
    "        data=dataset_name,\n",
    "        evaluators=[qa_evaluator, labeled_helpfulness_evaluator],\n",
    "        metadata={\"revision_id\": name},\n",
    "        experiment_prefix=name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics comparison of these retrievers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity(mode=relevant)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive</th>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.646875</td>\n",
       "      <td>0.946393</td>\n",
       "      <td>0.335747</td>\n",
       "      <td>0.078386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25</th>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.542519</td>\n",
       "      <td>0.505625</td>\n",
       "      <td>0.714447</td>\n",
       "      <td>0.184357</td>\n",
       "      <td>0.069874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contextual_compression</th>\n",
       "      <td>0.926042</td>\n",
       "      <td>0.659385</td>\n",
       "      <td>0.719375</td>\n",
       "      <td>0.942020</td>\n",
       "      <td>0.317060</td>\n",
       "      <td>0.050038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_query</th>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.679107</td>\n",
       "      <td>0.666250</td>\n",
       "      <td>0.942995</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>0.064683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_document</th>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.666752</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.944654</td>\n",
       "      <td>0.341270</td>\n",
       "      <td>0.143266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.701780</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.945188</td>\n",
       "      <td>0.238079</td>\n",
       "      <td>0.173059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_recall  faithfulness  \\\n",
       "naive                         0.945833      0.768603   \n",
       "bm25                          0.526042      0.542519   \n",
       "contextual_compression        0.926042      0.659385   \n",
       "multi_query                   0.956250      0.679107   \n",
       "parent_document               0.987500      0.666752   \n",
       "ensemble                      0.975000      0.701780   \n",
       "\n",
       "                        factual_correctness(mode=f1)  answer_relevancy  \\\n",
       "naive                                       0.646875          0.946393   \n",
       "bm25                                        0.505625          0.714447   \n",
       "contextual_compression                      0.719375          0.942020   \n",
       "multi_query                                 0.666250          0.942995   \n",
       "parent_document                             0.661250          0.944654   \n",
       "ensemble                                    0.665625          0.945188   \n",
       "\n",
       "                        context_entity_recall  \\\n",
       "naive                                0.335747   \n",
       "bm25                                 0.184357   \n",
       "contextual_compression               0.317060   \n",
       "multi_query                          0.268373   \n",
       "parent_document                      0.341270   \n",
       "ensemble                             0.238079   \n",
       "\n",
       "                        noise_sensitivity(mode=relevant)  \n",
       "naive                                           0.078386  \n",
       "bm25                                            0.069874  \n",
       "contextual_compression                          0.050038  \n",
       "multi_query                                     0.064683  \n",
       "parent_document                                 0.143266  \n",
       "ensemble                                        0.173059  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the retriever performance metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    name: result.to_pandas().mean(numeric_only=True).to_dict()\n",
    "    for name, result in all_results.items()\n",
    "}).T\n",
    "\n",
    "comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the latency and cost of these retrievers using langsmith\n",
    "\n",
    "Here's the langsmith trace that compares these 6 retriever strategies: [https://smith.langchain.com/public/46f43d3d-779e-4c6d-96b3-e85177292ed2/d](https://smith.langchain.com/public/46f43d3d-779e-4c6d-96b3-e85177292ed2/d)\n",
    "\n",
    "Comparison of the latency by retriever:\n",
    "![Latency Comparison by Retriever](latency_retriever.png)\n",
    "\n",
    "\n",
    "Comparison of the cost by retriever:\n",
    "![Cost Comparison by Retriever](cost_retriever.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion on Retrieval Methods\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Retriever | Cost | P50 Latency | Context Recall | Faithfulness | Factual Correctness | Answer Relevancy | Context Entity Recall | Noise Sensitivity |\n",
    "|-----------|------|-------------|---------------|-------------|--------------------|-----------------|--------------------|------------------|\n",
    "| naive | ~$0.0035 | ~2.1s | 0.946 | 0.769 | 0.647 | 0.946 | 0.336 | 0.078 |\n",
    "| bm25 | ~$0.0018 | ~1.2s | 0.526 | 0.543 | 0.506 | 0.714 | 0.184 | 0.070 |\n",
    "| contextual_compression | ~$0.002 | ~1.8s | 0.926 | 0.659 | 0.719 | 0.942 | 0.317 | 0.050 |\n",
    "| multi_query | ~$0.0047 | ~3.1s | 0.956 | 0.679 | 0.666 | 0.943 | 0.268 | 0.065 |\n",
    "| parent_document | ~$0.0029 | ~1.8s | 0.988 | 0.667 | 0.661 | 0.945 | 0.341 | 0.143 |\n",
    "| ensemble | ~$0.0063 | ~3.9s | 0.975 | 0.702 | 0.666 | 0.945 | 0.238 | 0.173 |\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For this wellness dataset, the **naive retriever** actually provides great overall balance of performance, cost, and latency. Performance wise, it has great context recall score (0.95), highest faithfulness score (0.77), high answer relevancy (0.95), and other scores are all decently well. Cost/latency wise, it has a moderate cost and latency. For example, although the cost is higher than bm25, the performance is much better; although ensemble has twice the cost than naive, the marginal performance gain of ensemble is actually minimal on this golden dataset. Same trend for latency as well.\n",
    "\n",
    "**Parent document** is a strong alternative which I may also choose instead of naive retriever. It has the highest context recall score (0.99), and comparable scores to the naive retriever in other metrics except faithfulness and noise sensitivity. The relatively high noise sensitivity (0.14) is because the large parent chunks could contain irrelevant information. Faithfulness is lower also likely because parent document contains more irrelevant information which caused faithfuless score to be lower. But I think these metrics has smaller effect in actual user experience compared to other metrics. On the other hand, parent document has lower cost and latency than naive, which makes it strong alternative to the native method. \n",
    "\n",
    "So for this dataset, I would choose either naive retriever or parent document. But since parent document has lower cost/latency with comparable if not better metrics than naive, I would likely start with parent document approach. We can iterate and change the retrieval strategy based on actual user feedback.\n",
    "\n",
    "#### Appendix: analysis of other retrievers\n",
    "\n",
    "**Contextual compression** is a good alternative â€” it achieves the best factual correctness (0.72) and lowest noise sensitivity (0.05), meaning it retrieves the most precise context. Its cost and latency are also decent, although the cost from Langsmith may not be accurate since we need to do re-rank using Cohere, which might incur additional cost.\n",
    "\n",
    "**Ensemble and multi_query** offer marginal improvements over naive/parent document but at significantly higher cost (1.3-1.8x) and latency (1.5-1.9x), making them poor value tradeoffs. For multi-query, this is likely because we introduce extra LLM calls to create additional queries, while ensemble executes all the retrieval strategies, all of which introduce much higher cost and latency. \n",
    "\n",
    "**BM25** is clearly the weakest for this golden dataset with larger performance gap (e.g., context recall 0.53 vs 0.95+), although it is the cheapest and fastest. BM25 makes more sense if the user query contains more term specific items.\n",
    "\n",
    "To me the key takeaway is that since our source document is a single, well-structured document with clear topical sections, simple naive retrieval works decently well. As our text corpus becomes more complicated like having various different documents across various domains/topics, more advanced strategies like ensemble and multi_query may show greater benefits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class notes:\n",
    "\n",
    "\n",
    "#### Golden dataset \n",
    "- How many test samples are need\n",
    "    - 10-15 samples\n",
    "- Whether to use unrolled or abstract\n",
    "- Distrubtion of samples\n",
    "- which LLM to use\n",
    "    - consider cost, latency, performance\n",
    "- human vs synthetic generated data\n",
    "\n",
    "#### Retriever\n",
    "- determine the number of docs/chunks to retrieve\n",
    "- parent/child document chunk size\n",
    "\n",
    "#### Metrics \n",
    "- Determine which ragas metrics to use\n",
    "- how many runs to evaluate \n",
    "- how to measure latency (across a few runs) and cost (embedding cost, LLM cost)\n",
    "- Is faster retrieval better or more accurate retrieval better, what tradeoffs are you willing to pay (more cost for better performance or lower cost for faster performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
