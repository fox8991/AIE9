{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Build: Semantic Chunking Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document length: 16206 characters\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/HealthWellnessGuide.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "with open(\"data/HealthWellnessGuide.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f\"Document length: {len(raw_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement semantic chunking using the following steps:\n",
    "1. Split the document into individual sentences using `nltk.sent_tokenize`\n",
    "2. Embed all sentences\n",
    "3. Greedily merge adjacent sentences: if the next sentence is semantically similar\n",
    "   (cosine similarity > threshold) to the current chunk AND adding it stays under\n",
    "   the max chunk size, merge it in. Otherwise, close the chunk and start a new one.\n",
    "4. Second pass: greedily merge adjacent chunks using the same logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def split_into_sentences(text: str) -> list[str]:\n",
    "    \"\"\"Split text into sentences using nltk sentence tokenizer.\n",
    "\n",
    "    Splits by line breaks first (to respect bullet points, headers, etc.),\n",
    "    then applies sent_tokenize within each line to handle multi-sentence lines.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        sentences.extend(sent_tokenize(line))\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def _greedy_merge(texts: list[str], text_embeddings: list[np.ndarray], similarity_threshold: float, max_chunk_size: int) -> tuple[list[str], list[np.ndarray]]:\n",
    "    \"\"\"Greedily merge adjacent texts based on semantic similarity.\n",
    "\n",
    "    Compares each next text's embedding against the average embedding of the\n",
    "    current group. Merges if similarity >= threshold and size <= max.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    chunk_embeddings = []\n",
    "\n",
    "    current_texts = [texts[0]]\n",
    "    current_embs = [text_embeddings[0]]\n",
    "\n",
    "    for i in range(1, len(texts)):\n",
    "        current_avg_emb = np.mean(current_embs, axis=0)\n",
    "        sim = cosine_similarity(current_avg_emb, text_embeddings[i])\n",
    "\n",
    "        potential_text = \" \".join(current_texts + [texts[i]])\n",
    "\n",
    "        if sim >= similarity_threshold and len(potential_text) <= max_chunk_size:\n",
    "            current_texts.append(texts[i])\n",
    "            current_embs.append(text_embeddings[i])\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_texts))\n",
    "            chunk_embeddings.append(np.mean(current_embs, axis=0))\n",
    "            current_texts = [texts[i]]\n",
    "            current_embs = [text_embeddings[i]]\n",
    "\n",
    "    # Flush last chunk\n",
    "    chunks.append(\" \".join(current_texts))\n",
    "    chunk_embeddings.append(np.mean(current_embs, axis=0))\n",
    "\n",
    "    return chunks, chunk_embeddings\n",
    "\n",
    "\n",
    "def semantic_chunk(\n",
    "    text: str,\n",
    "    embedding_model,\n",
    "    similarity_threshold: float = 0.25,\n",
    "    max_chunk_size: int = 750,\n",
    ") -> list[str]:\n",
    "    \"\"\"Greedily chunk text based on semantic similarity.\n",
    "\n",
    "    Pass 1: Merge adjacent similar sentences into chunks.\n",
    "    Pass 2: Merge adjacent similar chunks into larger chunks.\n",
    "\n",
    "    Args:\n",
    "        text: The full document text.\n",
    "        embedding_model: An embedding model with embed_documents().\n",
    "        similarity_threshold: Cosine similarity threshold for merging.\n",
    "        max_chunk_size: Maximum chunk size in characters.\n",
    "\n",
    "    Returns:\n",
    "        A list of chunk strings.\n",
    "    \"\"\"\n",
    "    sentences = split_into_sentences(text)\n",
    "    if not sentences:\n",
    "        return []\n",
    "\n",
    "    # Embed all sentences at once\n",
    "    sentence_embeddings = embedding_model.embed_documents(sentences)\n",
    "    sentence_embeddings = [np.array(e) for e in sentence_embeddings]\n",
    "\n",
    "    # Greedily merge adjacent similar sentences\n",
    "    chunks, chunk_embeddings = _greedy_merge(sentences, sentence_embeddings, similarity_threshold, max_chunk_size)\n",
    "\n",
    "    # Greedily merge adjacent similar chunks\n",
    "    merged_chunks, _ = _greedy_merge(chunks, chunk_embeddings, similarity_threshold, max_chunk_size)\n",
    "\n",
    "    return merged_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 33\n",
      "Chunk sizes (chars): min=2, max=800, mean=487\n",
      "\n",
      "--- Chunk 0 (778 chars) ---\n",
      "The Personal Wellness Guide A Comprehensive Resource for Health and Well-being PART 1: EXERCISE AND MOVEMENT Chapter 1: Understanding Exercise Basics Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weight, reduce the risk of disease, strengthen bones and muscles, and improve your ability to do everyday activities. The four main types of exercise are aerobic (cardio), strength training, flexibility, and balance exercises. A well-rounded fitness routine includes all four types. Adults should aim for at least 150 minutes of moderate-intensity aerobic activity per week, along with muscle-strengthening activities on 2 or more days per week. Chapter 2: Exercises for Common Problems\n",
      "\n",
      "--- Chunk 1 (744 chars) ---\n",
      "Lower Back Pain Relief Lower back pain affects approximately 80% of adults at some point in their lives. Gentle stretching and strengthening exercises can help alleviate discomfort and prevent future episodes. Recommended exercises for lower back pain include: - Cat-Cow Stretch: Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions. - Bird Dog: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side. - Partial Crunches: Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off floor. Hold briefly, then lower. Do 8-12 repetitions.\n",
      "\n",
      "--- Chunk 2 (755 chars) ---\n",
      "- Knee-to-Chest Stretch: Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs. - Pelvic Tilts: Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis up slightly. Hold for 10 seconds, repeat 8-12 times. Neck and Shoulder Tension Desk work and poor posture often lead to neck and shoulder tension. These exercises can provide relief: - Neck Rolls: Slowly roll your head in a circle, 5 times in each direction. - Shoulder Shrugs: Raise shoulders toward ears, hold for 5 seconds, then release. Repeat 10 times. - Chest Opener: Clasp hands behind back, squeeze shoulder blades together, and lift arms slightly. Hold for 15-30 seconds.\n",
      "\n",
      "--- Chunk 3 (764 chars) ---\n",
      "- Chin Tucks: While sitting or standing tall, pull your chin back to create a \"double chin.\" Hold for 5 seconds, repeat 10 times. Chapter 3: Building a Workout Routine Starting a new exercise routine can feel overwhelming. The key is to start slowly and gradually increase intensity and duration over time. Beginner Weekly Schedule: - Monday: 20-minute walk + 10 minutes stretching - Tuesday: 15 minutes bodyweight exercises (squats, push-ups, planks) - Wednesday: Rest or gentle yoga - Thursday: 20-minute walk + 10 minutes stretching - Friday: 15 minutes bodyweight exercises - Saturday: 30-minute recreational activity (swimming, cycling, hiking) - Sunday: Rest Progressive overload is the gradual increase of stress placed on the body during exercise training.\n",
      "\n",
      "--- Chunk 4 (92 chars) ---\n",
      "This can be achieved by increasing weight, reps, sets, or decreasing rest time between sets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned similarity_threshold and max_chunk_size so that the average chunk size is ~500 characters\n",
    "semantic_chunks = semantic_chunk(\n",
    "    raw_text,\n",
    "    embeddings,\n",
    "    similarity_threshold=0.23,\n",
    "    max_chunk_size=800,\n",
    ")\n",
    "\n",
    "sizes = [len(c) for c in semantic_chunks]\n",
    "print(f\"Number of chunks: {len(semantic_chunks)}\")\n",
    "print(f\"Chunk sizes (chars): min={min(sizes)}, max={max(sizes)}, mean={np.mean(sizes):.0f}\")\n",
    "print()\n",
    "\n",
    "for i, chunk in enumerate(semantic_chunks[:5]):\n",
    "    print(f\"--- Chunk {i} ({len(chunk)} chars) ---\")\n",
    "    print(chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation for Evaluation\n",
    "\n",
    "Generate synthetic test set using RAGAS. This will be used to evaluate both\n",
    "the baseline and the semantic chunking systems. Same approach as the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd392b198ae64ef897db08f433c47319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928cffc3c6484cabbc88a2a9e8f54d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3d3404e17140cab0008c6141d7de0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee6f9fd1dbd4c169ce0748f00db7c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968fafc15ac846f9b7d015e420295ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fb114fd81942308d797e2bdf953983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c187ac2ae24a45832ae1b1382c3969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7a481c5c34bc394c34c0385150e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0bae375b334598927c81afdd7122ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can Neck Rolls help with neck and shoulder...</td>\n",
       "      <td>[The Personal Wellness Guide A Comprehensive R...</td>\n",
       "      <td>Neck Rolls can provide relief from neck and sh...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what help lower back pain exercises</td>\n",
       "      <td>[The Personal Wellness Guide A Comprehensive R...</td>\n",
       "      <td>Gentle stretching and strengthening exercises ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what cbt-i do for sleep?</td>\n",
       "      <td>[PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...</td>\n",
       "      <td>Cognitive Behavioral Therapy for Insomnia (CBT...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Cognitive Behavioral Therapy for Insom...</td>\n",
       "      <td>[PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...</td>\n",
       "      <td>Cognitive Behavioral Therapy for Insomnia (CBT...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key signs of poor work-life balan...</td>\n",
       "      <td>[PART 5: BUILDING HEALTHY HABITS Chapter 13: T...</td>\n",
       "      <td>According to Chapter 19, signs of poor work-li...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wut are the main tipz for boostin immune funct...</td>\n",
       "      <td>[PART 5: BUILDING HEALTHY HABITS Chapter 13: T...</td>\n",
       "      <td>Chapter 18 recomends the following for boostin...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What strategies from Chapter 9 can help manage...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Chapter 9 outlines several strategies for mana...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drawing on the guidance from Chapter 7 regardi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Establishing a consistent sleep schedule, as r...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the guidance in Chapter 9 on understa...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>Chapter 9 discusses insomnia as difficulty fal...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do the strategies for managing insomnia in...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>The strategies for managing insomnia in Chapte...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Drawing on the insights from Chapter 7 and Cha...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...</td>\n",
       "      <td>By integrating the knowledge from Chapter 7, w...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How can Neck Rolls help with neck and shoulder...   \n",
       "1                 what help lower back pain exercises   \n",
       "2                            what cbt-i do for sleep?   \n",
       "3   What is Cognitive Behavioral Therapy for Insom...   \n",
       "4   What are the key signs of poor work-life balan...   \n",
       "5   Wut are the main tipz for boostin immune funct...   \n",
       "6   What strategies from Chapter 9 can help manage...   \n",
       "7   Drawing on the guidance from Chapter 7 regardi...   \n",
       "8   How does the guidance in Chapter 9 on understa...   \n",
       "9   How do the strategies for managing insomnia in...   \n",
       "10  Drawing on the insights from Chapter 7 and Cha...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [The Personal Wellness Guide A Comprehensive R...   \n",
       "1   [The Personal Wellness Guide A Comprehensive R...   \n",
       "2   [PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...   \n",
       "3   [PART 3: SLEEP AND RECOVERY Chapter 7: The Sci...   \n",
       "4   [PART 5: BUILDING HEALTHY HABITS Chapter 13: T...   \n",
       "5   [PART 5: BUILDING HEALTHY HABITS Chapter 13: T...   \n",
       "6   [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "7   [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "8   [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "9   [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "10  [<1-hop>\\n\\nPART 5: BUILDING HEALTHY HABITS Ch...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Neck Rolls can provide relief from neck and sh...   \n",
       "1   Gentle stretching and strengthening exercises ...   \n",
       "2   Cognitive Behavioral Therapy for Insomnia (CBT...   \n",
       "3   Cognitive Behavioral Therapy for Insomnia (CBT...   \n",
       "4   According to Chapter 19, signs of poor work-li...   \n",
       "5   Chapter 18 recomends the following for boostin...   \n",
       "6   Chapter 9 outlines several strategies for mana...   \n",
       "7   Establishing a consistent sleep schedule, as r...   \n",
       "8   Chapter 9 discusses insomnia as difficulty fal...   \n",
       "9   The strategies for managing insomnia in Chapte...   \n",
       "10  By integrating the knowledge from Chapter 7, w...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   single_hop_specifc_query_synthesizer  \n",
       "6   multi_hop_specific_query_synthesizer  \n",
       "7   multi_hop_specific_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RAG - Fixed-size Chunking + Naive Retrieval\n",
    "\n",
    "Re-use the baseline RAG system using `RecursiveCharacterTextSplitter` (chunk_size=500) with naive top-k retrieval (i.e., no reranking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline chunks: 44\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Fixed-size chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "baseline_split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"Baseline chunks: {len(baseline_split_docs)}\")\n",
    "\n",
    "# Vector store\n",
    "baseline_client = QdrantClient(\":memory:\")\n",
    "baseline_client.create_collection(\n",
    "    collection_name=\"baseline\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "baseline_vector_store = QdrantVectorStore(\n",
    "    client=baseline_client,\n",
    "    collection_name=\"baseline\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "_ = baseline_vector_store.add_documents(documents=baseline_split_docs)\n",
    "\n",
    "# Naive retriever (top-k, no reranking)\n",
    "baseline_retriever = baseline_vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "RAG_PROMPT = \"\"\"You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "\n",
    "def baseline_retrieve(state):\n",
    "    retrieved_docs = baseline_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"response\": response.content}\n",
    "\n",
    "\n",
    "baseline_graph = StateGraph(State).add_sequence([baseline_retrieve, generate])\n",
    "baseline_graph.add_edge(START, \"baseline_retrieve\")\n",
    "baseline_graph = baseline_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercises that help with lower back pain include:\n",
      "- Cat-Cow Stretch: alternately arching and sagging your back while on hands and knees, doing 10-15 repetitions.\n",
      "- Bird Dog: extending opposite arm and leg from hands and knees, holding each for 5 seconds, and doing 10 repetitions per side.\n",
      "- Pelvic Tilts: lying on your back with knees bent, tilting your pelvis to flatten your back against the floor, holding for 10 seconds, and repeating 8-12 times.\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "response = baseline_graph.invoke({\"question\": \"What exercises help with lower back pain?\"})\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "baseline_dataset = copy.deepcopy(dataset)\n",
    "\n",
    "for test_row in baseline_dataset:\n",
    "    response = baseline_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2aa07fd219945e2918776351a2a907e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.6019, 'faithfulness': 0.6578, 'factual_correctness': 0.6073, 'answer_relevancy': 0.9535, 'context_entity_recall': 0.3586, 'noise_sensitivity_relevant': 0.1149}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import EvaluationDataset, evaluate, RunConfig\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "metrics = [LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()]\n",
    "\n",
    "baseline_eval_dataset = EvaluationDataset.from_pandas(baseline_dataset.to_pandas())\n",
    "\n",
    "baseline_result = evaluate(\n",
    "    dataset=baseline_eval_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Chunking RAG + Naive Retrieval\n",
    "\n",
    "Build a second RAG system using semantic chunks with the same naive top-k retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic chunks: 33\n"
     ]
    }
   ],
   "source": [
    "semantic_documents = [Document(page_content=chunk) for chunk in semantic_chunks]\n",
    "print(f\"Semantic chunks: {len(semantic_documents)}\")\n",
    "\n",
    "# Vector store\n",
    "semantic_client = QdrantClient(\":memory:\")\n",
    "semantic_client.create_collection(\n",
    "    collection_name=\"semantic\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "semantic_vector_store = QdrantVectorStore(\n",
    "    client=semantic_client,\n",
    "    collection_name=\"semantic\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "_ = semantic_vector_store.add_documents(documents=semantic_documents)\n",
    "\n",
    "# Naive retriever (top-k, no reranking)\n",
    "semantic_retriever = semantic_vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_retrieve(state):\n",
    "    retrieved_docs = semantic_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "semantic_graph = StateGraph(State).add_sequence([semantic_retrieve, generate])\n",
    "semantic_graph.add_edge(START, \"semantic_retrieve\")\n",
    "semantic_graph = semantic_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercises that help with lower back pain include:\n",
      "\n",
      "- Cat-Cow Stretch: Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\n",
      "- Bird Dog: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\n",
      "- Partial Crunches: Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off floor. Hold briefly, then lower. Do 8-12 repetitions.\n",
      "- Knee-to-Chest Stretch: Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\n",
      "- Pelvic Tilts: Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis up slightly. Hold for 10 seconds, repeat 8-12 times.\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "response = semantic_graph.invoke({\"question\": \"What exercises help with lower back pain?\"})\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Semantic Chunking with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_dataset = copy.deepcopy(dataset)\n",
    "\n",
    "for test_row in semantic_dataset:\n",
    "    response = semantic_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac97051aa1843a1866b3c2893b403f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[53]: AttributeError('StringIO' object has no attribute 'statements')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8604, 'faithfulness': 0.6264, 'factual_correctness': 0.6055, 'answer_relevancy': 0.9584, 'context_entity_recall': 0.3997, 'noise_sensitivity_relevant': 0.1663}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_eval_dataset = EvaluationDataset.from_pandas(semantic_dataset.to_pandas())\n",
    "\n",
    "semantic_result = evaluate(\n",
    "    dataset=semantic_eval_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "semantic_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Compare and Contrast Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline (Fixed-size)</th>\n",
       "      <th>Semantic Chunking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.8604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factual_correctness</td>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context_entity_recall</td>\n",
       "      <td>0.3586</td>\n",
       "      <td>0.3997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>noise_sensitivity_relevant</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.1663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Metric Baseline (Fixed-size) Semantic Chunking\n",
       "0              context_recall                0.6019            0.8604\n",
       "1                faithfulness                0.6578            0.6264\n",
       "2         factual_correctness                0.6073            0.6055\n",
       "3            answer_relevancy                0.9535            0.9584\n",
       "4       context_entity_recall                0.3586            0.3997\n",
       "5  noise_sensitivity_relevant                0.1149            0.1663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_result.scores)\n",
    "semantic_df = pd.DataFrame(semantic_result.scores)\n",
    "\n",
    "baseline_means = baseline_df.mean()\n",
    "semantic_means = semantic_df.mean()\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Metric\": baseline_means.index,\n",
    "    \"Baseline (Fixed-size)\": [f\"{v:.4f}\" for v in baseline_means.values],\n",
    "    \"Semantic Chunking\": [f\"{v:.4f}\" for v in semantic_means.values],\n",
    "})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The semantic chunking approach provides the biggest gain in `context_recall` compared to the baseline fixed size chunking, from 0.6019 to 0.8604.\n",
    "\n",
    "This is reasonable since the fixed size chunking around 500 chars could split the discussions of a same topic over multiple chunks; while the semantic chunking approach could keep the full topic together. During retrieval phase, the retriever is able to retrieve much more ground-truth claims. \n",
    "\n",
    "Most other metrics are relatively flat though, which shows the LLM could provide reasonable answers based on the retrieved chunks for both baselien and semnatic chunking approach. So this shows we may need to apply additional retrieval improvements like re-ranking to further improve the results, like what we did in the first assignemnt. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
